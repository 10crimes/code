
\section{Locating the Vertical Vanishing Point} \label{sec-vertvanish}


In a perspective view of a document, the spacing between adjacent lines of text
in the image will vary relative to their distance from the camera.  This is the
same effect that causes the railway sleepers beneath a train track to appear
closer together as they approach the horizon. This change in spacing can be used
to determine the angle at which the document is tilted, and hence the vertical
vanishing point $\myvec{V}$ of the text plane. 

In \cite{planargrouping}, Schaffalitzky and Zisserman group repetitive elements
in an image (such as railings in front of a building) and use them to detect 
vanishing points and lines. 
They fit a vanishing point model to a group of objects using maximum likelihood
estimation, providing the image coordinates of all relevant pixels as data for
the fitting. Our approach is similar, except that for this application we have 
already performed recognition of the paragraphs of text and may therefore 
extract more representative data for the fitting
(in the form of line position and line spacing pairs).
%We too employ Marquardt-Levenberg fitting %MLE
%and RANSAC, and will present the functions used. However, 
It is important to
note that in \cite{planargrouping}, the objects used contain regularly spaced
features in the real-world, whereas our text data is corrupted by irregular
spacings between paragraph lines and by various font sizes.

% He does not explain the details of his algorithm, but does say he uses
% Marquardt-Levenberg fitting, as do we.  He uses the image coordinates of
% all relevant pixels as data for fitting, whereas we process the image to
% extract (a small number of) spacings measurements and use these
% measurements as data.  He does not report the fitting/RANSAC equation he
% used.  (We do.)

\subsection{Fitting using Line Spacing}
Our overall method is as follows. After first transforming the image to 
simplify the problem, we  extract observations of the altitude of 
each line in the image.  A model of the geometry will allow us to express 
these observations as a function of the paragraph's orientation.  By 
fitting the observations to the function, we will obtain the desired 
parameters of the orientation, and hence the position of the vanishing point.  
We show that a higher-order fitting function 
can assist in avoiding outliers. The whole process is now described in
further detail.

An appropriate rotation of the image plane about the z-axis will position the
baseline (found in the previous section - call it $\myvec{B}$) vertically, 
(see \reffig{zyspacings}). This rotation is equivalent to:

\begin{equation}
\myvec{B_{v}} = \left(\begin{array}{cc}\cos(\frac{\pi}{2}-\theta) ~ ~ -\sin(\frac{\pi}{2}-\theta)\\\sin(\frac{\pi}{2}-\theta) ~  ~  ~ ~ ~ \cos(\frac{\pi}{2}-\theta)\end{array}\right) \myvec{B} \label{uprightbaseline}
\end{equation}

{\parindent 0mm
where $\theta$ is the angle between $\myvec{B}$ and the horizontal.
Henceforth, we can disregard the $x$-coordinates and deal
solely in the $y,z$ plane. 
If we ignore spaces between paragraphs momentarily,
we can describe an ideal geometrical model in which
the bottom of a single paragraph is positioned
at $\myvec{P}$ with lines occurring at even spacings of distance $\myvec{Q}$.
The $n$th line from the bottom of the paragraph will lie at:
}


\begin{eqnarray}
\myvec{L}(n) = \myvec{P}+n\myvec{Q} \label{nthline}
\end{eqnarray}

and will appear in the image at an observable altitude of $y(n)$.
{\parindent 0mm
Using simple perspective projection ratios, we can relate the image points to the world position with:
%and will project to the point in the image plane
}
%\begin{eqnarray}
%y(n) = f \frac{ \myvec{L}(n)_y }{ \myvec{L}(n)_z } = f \frac{ \myvec{P}_y + n \myvec{Q}_y }{ \myvec{P}_z + n\myvec{Q}_z } \label{spacingspq}
%\end{eqnarray}

\begin{eqnarray}
\frac{y(n)}{f}  = \frac{ \myvec{L}(n)_y }{ \myvec{L}(n)_z }  \label{spacingspq1}
\end{eqnarray}
{\parindent 0mm
where $f$ is the focal length of the camera. Hence, the perspective projection
of the  $n$th line in the image plane, after substituting \refeqn{nthline} into
\refeqn{spacingspq1}, is: 
}
\begin{eqnarray}
y(n) =  f \frac{ \myvec{P}_y + n \myvec{Q}_y }{ \myvec{P}_z + n\myvec{Q}_z } \label{spacingspq}
\end{eqnarray}

{\parindent 0mm
with $y(\infty)$ giving the position of the vanishing line.
Without losing the nature of the projection, we may scale the scene about the focal point in order to set $\myvec{P}_z$ to $f$, hence modelling the paragraph as if it touched the image plane.  In this case, $\myvec{P}_y=y(0)$,
and we may rewrite \refeqn{spacingspq} as:
}

\begin{eqnarray}
y(n) = U \frac{ 1 + nV }{ 1 + nW } \label{spacingsvweqn}
\end{eqnarray}

{ \parindent 0mm
with $U=y(0)$ and only two unknowns,
$V = {\myvec{Q}_y}/{\myvec{P}_y}$ and $W = {\myvec{Q}_z}/{\myvec{P}_z}$.
The cancelling of the focal length $f$ in this way means that the technique is applicable to images captured with any optical camera and the internal parameters of the original camera need not be known.

Equation (\ref{spacingsvweqn}) now relates the parameters $\{V,W\}$, which describe the
tilt of the document, to a set of points which may be extracted from the
image.
Observations for $y(n)$ are obtained by projecting the centroid of
each detected line of text onto the baseline $\myvec{B_v}$, to collect a set of
points $O(n)$.
% By projecting the centroids of the lines of text located in the image from the horizontal vanishing point onto the baseline, estimates for $y(n)$ may be obtained.  % for these points.
A least-squares fit of $O(n)$ to the function $y(n)$ should now yield values for $V$ and $W$, and hence the vertical vanishing point.

However, this fitting is only applicable to the ideal document with
equally-spaced lines. 
In reality, it is common for documents to contain
spaces between paragraphs,
lines of text which are not part of a regularly spaced block,
and unexpected extraneous elements.
% the $n$th line observed in the image may lose correspondence with the $n$th
% line in the paragraph model.
% For example, an outlier at position $n=K$ would cause all successive
% observations 
% When fitting the curve of $y(n)$ against $n$, one such outlier at $n=K$ would cause all succesive observations ($n>K$) to have 
The presence of such outliers in the data can break the correspondence between
the $n$th line in the ideal paragraph and the $n$th data point $O(n)$, which is
implied in the fitting of $O(n)$ to $y(n)$.
% In the presence of such outliers, fitting a set of points $(n,O(n))$ to the curve $(n,y(n))$ 
% is inappropriate, since any outlier will break the correspondence between the $x$
% and $y$ coordinates of successive points.
For example, in \reffig{poorfitting}, data point (or line number) 8 is an undesirable outlier
which has shifted all successive points one position along the horizontal $n$-axis,
resulting in a poor fit.
Due to its proximity, the point was not even rejected when RANSAC was used in
 the fitting.
% Whilst RANSAC has the potential to remove such outliers, it failed to do so in this case, and it would always fail in the case where


% in the presence of outliers is problematic, since we cannot guarantee the linkage of all the point's x and y coordinates.
% To fit a curve of position $y(n)$ against line number $n$ would be unwise in this situation.
% An alternative curve which may be taken from the data and remains unaffected by line number, is the ratio of 
% Fortunately it is possible to derive two $n$-invariant observations from the image which
% To prevent the progression of an outlier through successive observations, we must use 
However, we can remove the direct influence of $n$, by instead fitting
% It is therefore preferable to remove the direct dependence of the points on $n$
% by instead fitting
the curve of {\em line spacing} $Y_n$ against {\em position} $X_n$, defined by:


\begin{eqnarray}
Y_n = y(n+1)-y(n) & \mbox{~~~~~~~~~~~~~~~ \it line spacing} \label{linespacingsdefneqn} \\
X_n = y(n) & \mbox{~~~~~~~~~~~~~~~ \it line position} \label{linepositiondefneqn}
\end{eqnarray}

With this approach, any irregularities in line spacing will appear as isolated
outliers in the data, but will not propagate through the remaining points. % $X_n$.
% points.
By substituting \refeqn{spacingsvweqn}
into the definition of line spacing \refeqn{linespacingsdefneqn}, the curve of
$Y$ in terms of $X$ may be written as: 
%in two parts:
}

\begin{equation}
Y(X) = U \frac{1+(n(X)+1)V}{1+(n(X)+1)W} - U \frac{1+n(X)V}{1+n(X)W}
\label{fittingeqn}
\end{equation}

{\parindent 0mm
with $n$ in terms of $X$ derived by a similar substitution of \refeqn{spacingsvweqn} into the definition of line position \refeqn{linepositiondefneqn} and rearrangement to:
}

\begin{equation}
n(X) = \frac{X-U}{UV-XW}
\label{nfromxeqn}
\end{equation}

% Initial parameters $V$ and $W$ are chosen for line fitting using a simple estimate.
Initial values for the parameters $V=2.0$ and $W=0.1$ were empirically chosen as 
seeds for the fitting.
% For thesis maybe:
% These seed values remain constant in our experiments, although for each fitting their signs must be set to correpond to the ordering of the data points (increasing or decreasing $y(n)$) and the general trend of $Y(n)$ (increasing or decreasing).
% for the error optimisation.
% However, due to the complexity of \refeqn{fittingeqn} and \refeqn{nfromxeqn}, many false
% local minima exist, one of which may be converged upon during fitting.
% Therefore, in order to ensure that parameters close to the global minimum are used as seeds,
To avoid the false local minima caused by the complexity of \refeqn{fittingeqn} and \refeqn{nfromxeqn},
we ensure that parameters close to the global minimum are used as seeds,
by making an initial fit with an approximation of \refeqn{fittingeqn}:

\begin{equation}
Y(X) = \frac{ UV }{ 1+n(X)W }
\end{equation}

which refines the parameters before the final fitting with \refeqn{fittingeqn}.
% This ensures that parameters close to the global minimum are obtained before the final fitting.
The dashed line in \reffig{goodfitting} shows that the outlier from \reffig{poorfitting} has now
affected two of the data points, but not the rest of the data.
Since the line spacings exhibit more clearly the irregularities of the points observed in the image,
RANSAC was able to easily reject these outliers, and produce a good fit (solid line in \reffig{goodfitting}).   % close to the ground truth.
% Unlike the fitting to $(n,y(n))$, fitting to $(y(n),Y(n))$ will give rise to the correct curve
In fact, the fitting using line spacings is able to cope with situations
when points are missing, presence of irrelevant points,
or a space between paragraphs causes a change in the phase of the line positions.
% % (However, it doesn't deal with adjacent paragraphs of different internal line spacing.)
% However, since the fitting achieved is still not perfect, we employ RANSAC to
% actually exclude apparent outliers from the final parameter fit.
% Once optimised, $V$ and $W$ are plugged into \refeqn{spacingsvweqn} to find the 



Once optimised, $V$ and $W$ may be substituted into
\refeqn{spacingsvweqn} to find the altitude of the horizon:
 
\begin{equation}
y(\infty) = \frac{UV} {W}
\end{equation}
 
% A graph of the final fitting for the running example is shown in \reffig{fittinggraph}.
After reversing the transformation made earlier in (\ref{uprightbaseline}) to
bring the baseline upright, this point will correspond to the location of the
vertical vanishing point in the original image.

%As with the horizontal vanishing point, the method is not suited to situations
%when the vertical vanishing point is close to infinity, which occurs when the
%pitch is low.
% \reffig{vvpaccuracy} shows the angular error of the vertical vector recovered
% for each image in the range of $0$ to $90^\circ$ in yaw and pitch using the
\subsection{Assessing Vertical Vanishing Point Accuracy}
\reffig{vvpaccuracy} shows the accuracy of recovery of the vertical vanishing
point for the whole range of $0$ to $90^\circ$ in yaw and pitch using the
methods described.  In \reffig{vvpaccuracya} it can be seen that, as expected,
intersecting the left and right margins $F_L$ and $F_R$ of a fully-justified block of text gives a
good estimate of the vertical vanishing point.  Also as expected and can be
observed in \reffig{vvpaccuracyb}, when such margins are used to estimate the
vertical vanishing point of a non-fully formatted paragraph (in this example a
left-justified one), performance is poor due to the paragraph's jagged edge.
However, when line
spacings are employed on centrally-justified and left-justified  paragraphs, as
in Figures \ref{vvpaccuracyc} and \ref{vvpaccuracyd} respectively, very good
results with low error rates are obtained. 
%Figures \ref{vvpaccuracyc} and \ref{vvpaccuracyd} show  examples of the accuracy when line
%spacings are employed on centrally-justified and left-justified  paragraphs.
This method provides good
results  for all of the simulated images except those
documents oriented beyond $80^\circ$ in pitch, where the algorithm begins to
fail. 
% The method provides comparable results over most of the simulated images, however for documents beyond $80^\circ$ in pitch the algorithm begins to fail.
As with the horizontal vanishing point in \refsect{locatehvpsect}, this may be
explained by the orientation of the document becoming nearly perpendicular to
the image plane. At such an extreme tilt, even if the lines of text are
separated correctly, their proximity in the image means there is little accuracy
in position and spacing for the curve fitting. In real world images, documents
at such extreme angles cannot practically be read or used by OCR once recovered,
hence this failure is not a great concern. The advantage of the line spacings
method is that it provides consistent results for paragraphs which are not 
fully-justified. 

%Finally, \reffig{vvpaccuracyd} displays a further example of the
%accuracy of the line spacings method for a whole range of orientations of
%left-justified paragraphs.

% In contrast, the poor performance of the margins method when dealing with documents which are not fully justified can be seen in \reffig{vvpaccuracyc}.


The results for these experiments, and the location of the horizontal vanishing
point in \refsect{locatehvpsect}, can be compared more closely in
\reftab{accuracytable}. 
The vanishing point (VP) error is calculated as the relative distance of the
vanishing point from its groundtruth, as described in \refsect{locatehvpsect} (see equation (\ref{Haccuracy})). 
The angular error is the difference in angle between the determined orientation of the
vertical vector of the text plane and the same vector from the groundtruth.
It can be seen that the accuracy of location of the vertical vanishing point is
good for both the margin intersection and the line spacings method. 
As rows 3 and 4 of \reftab{accuracytable} show, intersecting margins is not
suitable for documents with jagged edges giving a large angular error.
% Results for right-justified paragraphs are omitted since they are essentially equivalent to
% left-justified paragraphs.
Results for right-justified paragraphs have been omitted for brevity, and are of course comparable to those for left-justified paragraphs.
% We keep the  presentation of  our
% results simple by not showing any on right-justified paragraphs since their
% occurrance is very rare compared to other types.


Having found both of the  vanishing points of the plane, we may project two lines from each
to describe the left and right margins and the top and bottom limits of the
paragraph(s) in the image. 
These lines are intersected to form a quadrilateral enclosing the text,
as shown in \reffig{summaryfig}. % , which is expanded to frame the paragraph.
This quadrilateral is then used to recover a fronto-parallel viewpoint
of the document.


% Here is the best OCR result of images currently in paper:
% When a problem I try to remain humble, i a sin             tude.andbei
% that the outcome is : Of course, others may try to take advantage of you, and if your remaining detached only encourages unjust aggression,
% adopt a strong stand. Thia.
% however, should be done with
% compassion, and if it is necessary
% to express your views and
% take strong countermeasures,




\section{Recovery of fronto-parallel view} \label{sec-rectify}

% Given a partially calibrated camera for which only the focal length is unknown, a quadrilateral in the image which is known to correspond to some rectangle in the world is sufficient to determine the focal length.

In some applications we may not know the focal length of the camera used to capture the image.  However, having a quadrilateral in the image which is known to map to a rectangle in the scene is sufficient to recover the focal length of the camera.
% We shall briefly demonstrate ...

The vectors joining the focal point $\myvec{O}$ to the two vanishing points
$\myvec{H}$ and $\myvec{V}$ in the image plane are parallel to the horizontal
and vertical vectors of the document.  Since we expect these two vectors to be
mutually perpendicular in the scene, their scalar product will be:

\begin{equation}
( \myvec{H}_x , \myvec{H}_y , f ) \cdot ( \myvec{V}_x , \myvec{V}_y , f ) = 0
\end{equation}

This constraint expands to:

\begin{equation}
f = \sqrt{ - \myvec{H}_x \myvec{V}_x - \myvec{H}_y \myvec{V}_y }
\end{equation}

% \begin{equation}
% ( \myvec{H}_x , \myvec{H}_y ) \cdot ( \myvec{V}_x , \myvec{V}_y ) > 0 ~.
% \end{equation}

It is worth noting that if $ ( \myvec{H}_x , \myvec{H}_y ) \cdot ( \myvec{V}_x ,
\myvec{V}_y ) > 0 $, then no solution exists for $f$.  This situation means that
the angle between the origin and the two vanishing points on the image plane is
acute, and any corresponding quadrilateral cannot possibly be a rectangle in the
scene.  If such a quadrilateral is encountered during processing, we could
hypothesise that the document is in fact slanted on the text plane, or that the
quadrilateral does not actually correspond to a rectangular document in the
scene, and should be ignored. 

Having obtained the focal length of the camera, we may now recover a fronto-parallel view of the document.  The mapping into the recovered image takes place in world space rather than image space.
The grid of square pixels values in the original image project onto the document in the scene as quadrilaterals.
% The knowledge of the image pixel values is projected as a grid onto the document plane.
% The square pixels in the image project as quadrilaterals onto the document.
However, bi-cubic interpolation between these points on the document plane would be overkill,
unless data is being extracted for superresolution.
A simple perspective mapping with interpolation in the image plane is more efficient, and
will give rise to the same performance in the final stage of optical character recognition.
Therefore the pixel value of the document at position $X \in [0,1]$, $Y \in [0,1]$ from the top-left is found by:

\begin{equation}
\mbox{\em doc}(X,Y) = \mbox{\em image}(\frac{f\myvec{S}_x}{\myvec{S}_z},\frac{f\myvec{S}_y}{\myvec{S}_z})
\end{equation}


where
$\myvec{S} = \myvec{A} + X ( \myvec{B}-\myvec{A} ) + Y ( \myvec{C}-\myvec{A} )$
is the corresponding scene point on the document plane
derived from $\myvec{A}$, $\myvec{B}$ and $\myvec{C}$, i.e. the top-left, top-right and bottom-left corners of the
quadrilateral in the scene 
respectively, and $\mbox{\em image}(x,y)$ is the interpolated pixel value at point $(x,y)$ in the image.


\reffig{pprecover} shows the rectified images of the examples in
\reffig{linesegfig}. Further examples in \reffig{againmoreppresults} and 
\reffig{evenmoreppresults} show the recovery of various paragraphs, sometimes
multiple, sometimes single, and also multiple regions of text within a single image. 
% with left justified and centrally aligned text.
For example, in \reffig{arthurcclarke} a centrally-justified document containing
multiple paragraphs has been recovered at high resolution and is easily readable
or \reffig{emppra} shows the recovery of a segmented region of a book cover
which contains text of different sizes, and other image noise such as specularity.

% In \reffig{empprc} a left justified document was correctly identified and recovered, despite occlusion of part of the paragraph.
We put our rectified paragraphs through standard off-the-shelf OCR software,
however the final quality of character recognition is largely dependent on the quality of
the camera resolution, the distance to the document, and the OCR software used. 
We captured our images using a variety of cameras at various distances. 
In some recovered images, the OCR accuracy was below 50\%
while for others it was above 90\%.  For example, the image recovered in
\reffig{chem017recover} achieved 100\% accuracy.
It would be easy to have a series of images captured under suitable conditions
that result in close to 100\% recognition rates, but we have refrained from that 
and concentrated in this paper on showing that irrespective of the final OCR
result and under general conditions of image capture, the proposed method can recover the
text orientation from a wide range of perspective skews.  
%\reftab{ocrtable} shows that when we applied commercial OCR software to the image in \reffig{arthurcclarke},
%81\% of the characters and 84\% of the words were recognised correctly.
%\reffig{chem005recover} is an image of a large paragraph captured with a low-resolution camera.
%Since the document recovered from this image is only just readable by the human eye,
%the poor result from the OCR module is not unwarranted.
%Better performance can be expected from higher-resolution cameras, and controlled lighting conditions.
%This is demonstrated by the fact that one of our test images {\tt chem017},
%which is a closer view of the book in \reffig{chem015overlay} (not shown here),
%achieved 100\% accuracy.
% (One similar document in our test set achieved 100\% accuracy.)


%\begin{table}[t]
%  \begin{center}
%    % \begin{tabular}{|p{95mm}|l|l|}
%    \begin{tabular}{|p{35mm}|c|c|}
%      \hline
%      {\bf Image } & {\bf \%age correct characters} & {\bf \%age correct words} \\
%      \hline \hline
%      \reffig{chem015recover} & 79\% & 88\% \\
%      \hline
%      \reffig{arthurcclarke} & 81\% & 84\% \\
%      \hline
%      \reffig{chem005recover} & 50\% & 53\% \\
%		\hline
%      Test image {\tt chem017} & 100\% & 100\% \\
%		\hline
%   \end{tabular}
%  \end{center}
%  % \vspace*{-5mm}
%  \caption{Accuracy of Optical Character Recognition for recovered images.}
%  \label{ocrtable}
%\end{table}
