% Some shortened entries for ACIVS

@other{blank1,
  title="Ommitted",
  author="A. Nonymous"
}

@article{clark-ijdar-2001,
	author  = "P Clark and M Mirmehdi",
	title   = "Recognising Text in Real Scenes",
	journal = "International Journal on Document Analysis and Recognition",
	volume  = "4",
	number  = "4",
	year    = "2002",
	pages   = "243--257",
}
	% url     = "http://link.springer-ny.com/link/service/journals/10032/tocs/t2004004.htm",
	% note =    "To appear in {\em International Journal on Document Analysis and Recognition}",
	% publisher =    "IEEE",
%%  note =    "To appear in {\em International Journal on Document Analysis and Recognition}, vol. 4, no. 4",

@misc{planargrouping,
	author = "F Schaffalitzky and A Zisserman",
	title = "Planar Grouping for Automatic Detection of Vanishing Lines and Points",
	url = "http://citeseer.nj.nec.com/340408.html"
}


@inproceedings{clarkBMVC2000,
  title={Finding Text Regions Using Localised Measures},
  author={P Clark and M Mirmehdi},
  Booktitle={Proceedings of the 11th British Machine Vision Conference},
  pages={675--684},
  year={2000}
}


@inproceedings{rother0,
  title={A New Approach for Vanishing Point Detection in Architectural Environments},
  author={C Rother},
  Booktitle={Proc. 11th British Machine Vision Conference},
  pages={382--391},
  year={2000},
  keywords={Computer_Vision}
}

% NOTE: two identical papers follow: choose one!

@InProceedings{clarkICPR2000,
  title =        "Combining Statistical Measures to Find Image Text Regions",
  author =       "Paul Clark and Majid Mirmehdi",
  booktitle =    "Proceedings of the 15th International Conference on  Pattern Recognition",
  publisher =    "IEEE Computer Society",
  pages =        "450--453",
  month =        sep,
  year =         "2000"
}


@InProceedings{bolles81ransac-based,
    author = "R. Bolles and M. Fischler",
    title = "A {RANSAC}-based approach to model fitting and its application to finding
      cylinders in range data",
    booktitle = "Proc. 7th International Conference on Artificial Intelligence",
    pages = "637--643",
    year = "1981"
}



@InProceedings{justin,
  title = "Extracting Low Resolution Text with an Active Camera for {OCR}",
  author = "M. Mirmehdi and P. Clark and J. Lam",
  booktitle =    "Proceedings of the 9th Spanish Symposium on Pattern Recognition and Image Processing",
  pages =        "43--48",
  year =         "2001"
}


@inproceedings{joey1,
  title={Location and recovery of text on oriented surfaces},
  author={P Clark and M Mirmehdi},
  Booktitle={SPIE conference on Document Recognition and Retrieval VII, Vol. 3967},
  pages={267--277},
  month={January},
  year={2000}
}


@TechReport{partialSums,
  type = "Technical Report",
  number = "TR.245",
  institution = "Cambridge University",
  title = "Faster Spatial Image Processing using Partial Summation",
  author = "S. Hodges and R. J. Richards",
  pages = "203--217",
  year = "1996"
}

@TechReport{UCB98,
  type =         "Technical Report",
  number =       "CSD-98-999",
  institution =  "University of California, Berkeley",
  title =        "Multivalent Documents: {A} New Model for Digital
                 Documents",
  pages =        "44",
  year =         "1998",
  bibdate =      "March 13, 1998",
  author =       "R. Wilensky and T. A. Phelps",
  abstract =     "``Multivalent documents'' is a model of documents that
                 addresses some of the shortcomings one currently
                 encounters when manipulating documents in digital form.
                 In the multivalent document model, a document is
                 composed out of distributed data and program resources,
                 called layers and behaviors, respectively. The model
                 exposes virtually all aspects of document processing to
                 behaviors, and provides the means to compose these
                 components into a single coherent document. Behaviors
                 allow the model to be highly extensible, including the
                 capability to be extended to work with arbitrary
                 document formats. We have implemented the model in
                 Java, and developed behaviors that support multiple
                 document types (scanned page images, HTML, and ASCII)
                 and a number of different user-interface metaphors
                 (e.g., ``lenses'' and ``Notemarks''). The multivalent
                 document model enables one to better use digital
                 documents for tasks in which paper documents are still
                 otherwise superior to digital documents, such as
                 annotating someone else's document. We have shown how
                 the model is naturally conducive to realizing powerful
                 forms of distributed, open annotation by implementing a
                 variety of annotation types, some familiar and some
                 novel.",
}

@Book{Vapnik95,
  author =       "V. Vapnik",
  title =        "The Nature of Statistical Learning Theory",
  publisher =    "Springer Verlag",
  year =         "1995",
}     

@article{LI,
    author = "J. Li and R. Gray",
    title = "Context-based multiscale classification of document images using wavelet coefficient distributions",
    journal = "IEEE Transactions on Image Processing",
    number = "9",
    volume = "9",
    pages = "1604-16",
    year = "2000",
    url = "citeseer.nj.nec.com/li98context.html"
}



@article{LiJan00,
    author = "H. Li and D. Doermann and O. Kia",
    title = "Automatic identification of text in digital video key frames",
    journal = "IEEE Transactions on Image Processing",
		number = "9",
		volume = "1",
		pages = "147--156",
    year = "2000",
}



@TechReport{Lowe:1984,
  author =       "D. G. Lowe",
  title =        "{Perceptual Organization and Visual Recognition}",
  institution =  "Stanford University",
  year =         "1984",
  number =       "STAN-CS-84-1020",
  type =         "Report",
  address =      "Department of Computer Science",
  topics =       "K{\"u}nstliche Intelligenz / Raumwissen /
                 Neurowissenschaften / Psychophysik /
                 Mathematik/Geometrie / Konkreter Raum / Spatial
                 Reasoning",
}

@inproceedings{zisserman,
  author = "A. Criminisi and A. Zisserman",
  title = "Shape from texture: homogeneity revisited",
  booktitle = "Proceedings of the 11th British Machine Vision Conference",
  pages = "82--91",
  year = "2000"
}

@inproceedings{repetition,
    author = "F. Schaffalitzky and A. Zisserman",
    title = "Geometric Grouping of Repeated Elements within Images",
    booktitle = "Shape, Contour and Grouping in Computer Vision",
    pages = "165-181",
    year = "1999",
    url = "citeseer.nj.nec.com/schaffalitzky98geometric.html",
}
    % publisher = "Springer-Verlag",

@inproceedings{ribeiroBMVC,
  author = "E. Ribeiro and E. Hancock",
  title = "Detecting Multiple Texture Planes using Local Spectral Distortion",
  booktitle = "Proc. 11th British Machine Vision Conference",
  pages = "102--111",
  year = "2000"
}

@article{ribeiro,
  author = "E. Ribeiro and E. Hancock",
  title = "Estimating the Perpective Pose of Texture Planes using Spectral Analysis on the Unit Sphere", 
  journal = "To appear in Pattern Recogniton",
  pages = {},
  volume = {},
  number = {},
  year = 2002
}


@inproceedings{dance02,
  author = "C. R. Dance",
  title = "Perspective estimation for document images",
  Booktitle={SPIE conference on Document Recognition and Retrieval IX, Vol. 4670},
  pages={},
  month={January},
  year = "2002"
}

@Article{docsthrucams,
  author = "M. J. Taylor and A. Zappala and W. M. Newman and C. R. Dance",
  title = "Documents through cameras",
  journal = "Image and Vision Computing",
  year = "1999",
  volume = "17",
  pages = "831--844"
}

@Article{Lowe:1986,
  author =       "D. G. Lowe",
  title =        "{Three-dimensional object recognition from single
                 two-dimensional images}",
  journal =      "Artificial Intelligence",
  year =         "1986",
  volume =       "31",
  pages =        "355--395",
  topics =       "K{\"u}nstliche Intelligenz / Raumwissen / Spatial
                 Reasoning / Konkreter Raum / Mathematik/Geometrie",
}

@Article{MURIN,
  author =       "V. Murino and G. Foresti",
  title =        "{2D} into {3D H}ough-space mapping for planar object pose estimation",
  journal =      "Image and Vision Computing",
  year =         "1997",
  volume =       "15",
  pages =        "435-444",
}

@book{Lowe85,
   author    = {David G. Lowe},
   title     = {Perceptual Organization and Visual Recognition},
   year      = {1985},
   publisher = {Kluwer Academic Publishers},
   note      = {Perceptual organiztion, recognition.}
}

@TechReport{LIEN,
  type =         "Technical Report",
  number =       "TR-95-036",
  institution =  "University of Mannhein, Germany",
  title =        "Automatic text recognition in digital videos",
  year =         "1995",
  bibdate =      "May 13, 1996",
  url =          "ftp://pi4.informatik.uni-mannheim.de/pub/techreports/1995/TR-95-036.ps.gz",
  author =       "Rainer Lienhart and Frank Stuber",
  abstract =     "We have developed algorithms for automatic character
                 segmentation in motion pictures which extract
                 automatically and reliably the text in pre-title
                 sequences, credit titles, and closing sequences with
                 title and credits. The algorithms we propose make use
                 of typical characteristics of text in videos in order
                 to enhance segmentation and, consequently, recognition
                 performance. As a result, we get segmented characters
                 from video pictures. These can be parsed by any OCR
                 software. The recognition results of multiple instances
                 of the same character throughout subsequent frames are
                 combined to enhance recognition result and to compute
                 the final output. We have tested our segmentation
                 algorithms in a series of experiments with video clips
                 recorded from television and achieved good segmentation
                 results.",
}
  % month =        dec # " 1,",

@TechReport{BURGE2,
  type =         "Technical Report",
  number =       "1995TR-231",
  institution =  "Swiss Federal Institute of Technology, Zurich",
  title =        "Grouping Line Drawing Elements based upon their Area
                 Voronoi Tessellation",
  month =        apr # ",",
  year =         "1995",
  bibdate =      "August 21, 1996",
  author =       "Mark Burge and Gladys Monagan",
  abstract =     "We present an algorithm for grouping multipart
                 symbols, dashed lines, and character strings for
                 extraction from line drawings. Initially, the image
                 undergoes a lossless raster-to-vector conversion
                 creating as its vector representation an undirected
                 graph, a so-called run graph. Next, during
                 localization, the connected components of the run graph
                 are extracted and classified probabilistically from
                 their geometric features using a decision tree. The
                 result of the classification are sets of dashes, dots,
                 circles, symbols, and graphics. An area Voronoi
                 tessellation of the members of the sets is constructed,
                 from which a neighborhood graph is derived. In this
                 graph, the nodes represent the image elements and the
                 edges the connections to their nearest graph neighbors.
                 The graph is then traversed to group the members of the
                 various sets into candidate character strings, dashed
                 lines, and multipart symbols for extraction and for
                 input to different recognition modules. No a priori
                 font or other domain specific information is required
                 for the grouping: neighborhoods are guaranteed to be
                 minimal and complete, and no special geometrical
                 relationships among the elements are assumed. Results
                 from the localization and grouping are presented with
                 example images taken from those used by our Swiss
                 cadastral map understanding system.",
}

@Article{PEAKE,
  author =       "G. S. Peake and T. N. Tan",
  title =        "Script and Language Identification from Document
                 Images",
  journal =      "Lecture Notes in Computer Science",
  volume =       "1352",
  year =         "1997",
  coden =        "LNCSD9",
  ISSN =         "0302-9743",
  bibdate =      "Tue Apr 28 08:51:33 MDT 1998",
  acknowledgement = ack-nhfb,
}

@TechReport{WU3,
  title =        "Extracting Text From Greyscale Images",
  type =         "Technical Report",
  number =       "UM-CS-1995-088",
  language =     "English",
  month =        nov # ",",
  revision =     "April 3, 1996",
  year =         "1995",
  bibdate =      "April 3, 1996",
  author =       "V. Wu and R. Manmatha",
  url =          "ftp://ftp.cs.umass.edu/pub/techrept/1995/UM-CS-1995-088.ps",
  abstract =     "A suite of algorithms is presented to detect text in
                 images. The algorithms are shown to work on images with
                 a wide variety of backgrounds. The algorithms assume
                 that text is a special kind of texture characterized by
                 a frequency distribution different from the background.
                 An algorithm to remove the background and binarize the
                 detected text so that it can be processed by an OCR is
                 also presented. Experimental results are shown for a
                 number of images.",
  institution =  "University of Massachusetts, Amherst, Computer
                 Science",
}

@InProceedings{WU1,
  author =       "V. Wu and R. Manmatha and E. M. Riseman",
  title =        "Finding text in images",
  pages =        "3--12",
  booktitle =    "Proceedings of the 2nd {ACM} Int. Conf. on Digital Libraries",
  year =         "1997",
}
  % month =        jul,
  % publisher =    "ACM Press",

% "~23--26",
 
@InProceedings{WU2,
  author =       "Victor Wu and R. Manmatha and Edward M. Riseman",
  title =        "Finding text in images",
  pages =        "3--12",
  ISBN =         "0-89781-868-1",
  editor =       "Robert B. Allen and Edie Rasmussen",
  booktitle =    "Proceedings of the 2nd {ACM} International Conference
                 on Digital Libraries",
  month =        jul, 
  address =      "New York",
  year =         "1997",
}
  % publisher =    "ACM Press",

@Article{CAMP,
  author =       "P. Campadelli and D. Medici and R. Schettini",
  title =        "Using {Hopfield} Networks to Segment Color Images",
  journal =      "Lecture Notes in Computer Science",
  volume =       "974",
  year =         "1995",
  coden =        "LNCSD9",
  ISSN =         "0302-9743",
  bibdate =      "Sat May 11 13:45:32 MDT 1996",
  acknowledgement = ack-nhfb,
}

@Article{GOOL,
  author =       "L {Van Gool} and T Moons and D Ungureanu and A Oosterlinck",
  title =        "Characterization and detection of skewed symmetry",
  journal =      "Computer Vision and Image Understanding",
  volume =       "61",
  number =       "1",
  pages =        "138--150",
  year =         "1995",
  coden =        "CVIUF4",
  ISSN =         "1077-3142",
  bibdate =      "Fri Jan 31 15:09:26 MST 1997",
  affiliation =  "Katholieke Universiteit Leuven",
  affiliationaddress = "Heverlee, Belgium",
  classification = "723.5; 741.2; 921.3; 931.1",
  journalabr =   "Comput Vision Image Process",
  keywords =     "Affine transformations; Collinearity constraint;
                 Computer vision; Constraint theory; Mathematical
                 transformations; Parallelism constraint; Skewed
                 symmetry; Surfaces",
}

@TechReport{ZHANG,
  pages =        "39 p.",
  type =         "Technical Report",
  number =       "RR-2340",
  institution =  "Inria, Institut National de Recherche en Informatique
                 et en Automatique",
  title =        "Estimating Motion and Structure from Correspondences
                 of Line Segments Between Two Perspective Images",
  bibdate =      "September 1, 1994",
  author =       "Zhengyou Zhang",
  language =     "A",
  abstract =     "Dans cet article, nous pr\&eacute;sentons un
                 algorithme permettant d\&apos;estimer le mouvement et
                 la structure \&agrave; partir d\&apos;appariements de
                 segments de droite entre deux images perspectives.
                 \&agrave; notre connaissance, cet article est la
                 premi\&egrave;re tentative d\&apos;utilisation de
                 segments de droite \&agrave; cette fin. Contrairement
                 aux m\&eacute;thodes usuelles qui utilisent les droites
                 support de ces segments (pour lesquelles trois vues au
                 minimum sont n\&eacute;cessaires), nous montrons dans
                 cet article que deux vues sont en
                 g\&eacute;n\&eacute;ral suffisantes avec les segments
                 de droite. L\&apos;hypoth\&egrave;se cruciale qui entre
                 en compte est que deux segments de droite
                 appari\&eacute;s contiennent la projection d\&apos;une
                 partie commune d\&apos;un m\&ecirc;me segment de
                 l\&apos;espace. Cela est en fait d\&eacute;j\&agrave;
                 utilis\&eacute; pour la mise en correspondance de
                 segments entre plusieurs images. L\&apos;algorithme
                 propos\&eacute; a \&eacute;t\&eacute; test\&eacute;
                 avec des donn\&eacute;es synth\&eacute;tiques et
                 r\&eacute;elles, et d\&apos;excellents
                 r\&eacute;sultats ont \&eacute;t\&eacute; obtenus avec
                 des donn\&eacute;es r\&eacute;elles contenant une
                 centaine de segments. Les r\&eacute;sultats sont
                 comparables avec ceux obtenus avec la
                 st\&eacute;r\&eacute;o calibr\&eacute;e. We present in
                 this paper an algorithm for determining 3D motion and
                 structure from correspondences of nline segments
                 between two perspective images. To our knowledge, this
                 paper is the first investigation on use of line
                 segments in motion and structure from motion. Classical
                 methods use their geometric abstraction, namely
                 straight lines, but then three images are necessary. We
                 show in this paper that two views are in general
                 sufficient when using line segments. The assumption we
                 use is that two matched line segments contain the
                 projection of a common part of the corresponding line
                 segment in space. Indeed, this is what we use to match
                 line segments between different views. Both synthetic
                 and real data have been used to test the proposed
                 algorithm, and excellent results have been obtained
                 with real data containing about one hundred line
                 segments. The results are comparable with those
                 obtained with calibrated stereo.",
}

@Article{VIEV,
  author =       "T. Vieville and D. Lingrand",
  title =        "Using singular displacements for uncalibrated
                 monocular visual systems",
  journal =      "Lecture Notes in Computer Science",
  volume =       "1065",
  year =         "1996",
  coden =        "LNCSD9",
  ISSN =         "0302-9743",
  bibdate =      "Wed Aug 14 09:38:08 MDT 1996",
  acknowledgement = ack-nhfb,
}

@Article{CHEN,
  author =       "W.-Y. Chen and S.-Y. Chen",
  title =        "Adaptive page segmentation for color technical journals cover images",
  pages =        "855-877",
  journal =      "Image and Vision Computing",
  volume =       "16",
  number = "12",
  year =         "1998",
}
  % month =        "August",

@Article{STROUTH,
  author =       "C. Strouthopoulos and N. Papamarkos",
  title =        "Text identification for document image analysis using a neural network",
  journal =      "Image and Vision Computing",
  volume =       "16",
  year =         "1998",
}

@Article{ASTR,
  author =       "K. Aastroem and R. Cipolla and P. J. Giblin",
  title =        "Generalised epipolar constraints",
  journal =      "Lecture Notes in Computer Science",
  volume =       "1065",
  year =         "1996",
  coden =        "LNCSD9",
  ISSN =         "0302-9743",
  bibdate =      "Wed Aug 14 09:38:08 MDT 1996",
  acknowledgement = ack-nhfb,
}

@Conference{VINT,
  author =       "Sven Vinther and Roberto Cipolla",
  title =        "Towards 3{D} Object Model Acquisition and Recognition
                 using 3{D} Affine Invariants",
  booktitle =    "Proceedings of the 4th British Machine Vision Conference",
  year =         "1993",
  month =        jul,
  note =         "Kalman Filter",
}

@TechReport{COST,
  type =         "Technical Report",
  number =       "CS-94-220",
  title =        "A Multi-body Factorization Methods for Motion
                 Analysis",
  month =        sep,
  notes =        "Computer vision, image understanding, 3D vision, shape
                 from motion, motion analysis, invariants",
  pages =        "25",
  year =         "1994",
  bibdate =      "September 13, 1995",
  author =       "Joao Costeira and Takeo Kanade",
  abstract =     "The structure-from-motion problem has been extensively
                 studied in the field of computer vision. Yet, the bulk
                 of the existing work assumes that the scene contains
                 only a single moving object. The more realistic case,
                 where an unknown number of objects move in the scene,
                 has received little attention, especially for its
                 theoretical treatment. In this paper we present a new
                 method for separating and recovering the motion and
                 shape of multiple independently moving objects in a
                 sequence of images. The method does not require prior
                 knowledge of the number of objects, nor is it dependent
                 on on any grouping of features into an object at the
                 image level. For this purpose, we introduce a
                 mathematical construct of object shapes, called the
                 shape interaction matrix, which is invariant to both
                 the object motions and the selection of coordinate
                 systems. This invariant structure is computable solely
                 from the observed trajectories of image features
                 without grouping them into individual objects. Once the
                 matrix is computed, it allows for segmenting features
                 into objects by the process of transforming it into a
                 canonical form, as well as recovering the shape and
                 motion of each object.",
  institution =  "Carnegie Mellon University, School of Computer
                 Science",
}

@TechReport{JEZ,
  pages =        "26 p.",
  type =         "Technical Report",
  number =       "RR-1282",
  institution =  "Inria, Institut National de Recherche en Informatique
                 et en Automatique",
  title =        "Three-dimensional structure from a monocular sequence
                 of images",
  bibdate =      "August 1, 1990",
  author =       "J. L. Jezouin and Nicholas Ayache",
  language =     "A",
}

@InProceedings{MEY,
  author =       "F. Meyer and P. Bouthemy",
  title =        "Region--Based Tracking in an Image Sequence",
  pages =        "476--484",
  ISBN =         "3-540-55426-2",
  editor =       "Giulio Sandini",
  booktitle =    "Proceedings of Computer Vision ({ECCV} '92)",
  month =        "mai",
  series =       "LNCS",
  volume =       "588",
  publisher =    "Springer",
  address =      "Berlin, Germany",
  year =         "1992",
}

@Article{SEAL,
  author =       "W. Brent Seales and Olivier D. Faugeras",
  title =        "Building Three-Dimensional Object Models from Image
                 Sequences",
  journal =      "Computer Vision and Image Understanding",
  volume =       "61",
  number =       "3",
  pages =        "308--324",
  month =        may,
  year =         "1995",
  coden =        "CVIUF4",
  ISSN =         "1077-3142",
  bibdate =      "Sat Feb 8 07:08:38 MST 1997",
  acknowledgement = ack-nhfb,
  affiliation =  "Univ of Kentucky",
  affiliationaddress = "Lexington, KY, USA",
  classification = "723.2; 723.5; 741.2",
  journalabr =   "CVIU Comput Vision Image Understanding",
  keywords =     "Computer aided design; Computer aided manufacturing;
                 Computer graphics; Computer simulation; Computer
                 systems; Computer vision; Coordinate system; Edge
                 classification; Gray level images; Image
                 reconstruction; Image sequences; Image understanding;
                 Surface boundaries; Surface properties; Three
                 dimensional",
}

@TechReport{LING,
  pages =        "47 p.",
  type =         "Technical Report",
  number =       "RR-2687",
  institution =  "Inria, Institut National de Recherche en Informatique
                 et en Automatique",
  title =        "Dynamic Foveal 3{D} Sensing Using Affine Models",
  bibdate =      "October 1, 1995",
  author =       "Diane Lingrand and Thierry Vieville",
  language =     "A",
  abstract =     "On se propose d\&apos;\&eacute;tudier et de mettre au
                 point une m\&eacute;thode
                 d\&bsol;underline\&lcub;\&apos;analyse active\&rcub; de
                 la structure tridimensionelle d\&apos;une sc\&egrave;ne
                 au sein d\&apos;une s\&eacute;quence monoculaire
                 d\&apos;images dans le cas d\&apos;un syst\&egrave;me
                 \&bsol;underline\&lcub;non calibr\&eacute;\&rcub; et
                 d\&apos;un mod\&egrave;le
                 \&bsol;underline\&lcub;continu du mouvement\&rcub;.
                 Paradoxalement peut-\&ecirc;tre, ce probl\&egrave;me a
                 \&eacute;t\&eacute; peu trait\&eacute; dans la
                 litt\&eacute;rature, hormis dans
                 \&bsol;cite\&lcub;vieville-faugeras:95\&rcub;, mais
                 ceci de mani\&egrave;re relativement
                 pr\&eacute;liminaire. Dans tous les cas, on n\&apos;y
                 fait pas usage de strat\&eacute;gie de vision active.
                 Une revue compl\&egrave;te a d\&eacute;j\&agrave;
                 \&eacute;t\&eacute; \&eacute;tablie dans
                 \&bsol;cite\&lcub;tarabanis-allen- etal:95\&rcub;.
                 Cette difficult\&eacute; vient de la forte
                 complexit\&eacute; des \&eacute;quations qui impose une
                 mise en oeuvre lourde et donc a priori peu robuste et
                 interdit des d\&eacute;veloppements importants de
                 formes analytiques comme c\&apos;est le cas pour les
                 syst\&egrave;mes calibr\&eacute;s
                 \&bsol;cite\&lcub;vieville-clergue-etal:95,chaumette-
                 boukir:91,boukir:93\&rcub;. Afin de contourner cette
                 difficult\&eacute;, nous avons cherch\&eacute;
                 \&agrave; mettre en place une param\&eacute;trisation
                 simplifi\&eacute;e du probl\&egrave;me dans le cas de
                 deux ou plusieurs vues, consid\&eacute;rant une
                 sc\&egrave;ne contenant un ensemble d\&apos;objets
                 fixes et mettant en oeuvre une projection
                 orthographique sur la r\&eacute;tine. Dans ce cas, la
                 fusion entre deux vues est imm\&eacute;diate.
                 Gr\&acirc;ce \&agrave; la mise en place de
                 strat\&eacute;gies actives de perception, nous
                 d\&eacute;montrons qu\&apos;il est toujours possible
                 d\&apos;effectuer un mouvement tel que le
                 pr\&eacute;c\&eacute;dent mod\&egrave;le reste valable,
                 et reconstruisons ainsi tr\&egrave;s simplement la
                 sc\&egrave;ne observ\&eacute;e. Dans le cas o\&ugrave;
                 le mouvement est approximatif, i.e.\&nbsp;ne
                 v\&eacute;rifie que partiellement les contraintes
                 voulues, nous d\&eacute;montrons que le mod\&egrave;le
                 reste approximativement valide au voisinage de la
                 fov\&eacute;a. Au niveau exp\&eacute;rimental une
                 petite maquette est propos\&eacute;e qui prend en
                 entr\&eacute;e une s\&eacute;quence d\&apos;image et y
                 calcule les champs de mouvements d\&eacute;finis
                 pr\&eacute;c\&eacute;demment et la reconstruction
                 \&agrave; une tranformation affine de l\&apos;espace
                 pr\&egrave;s. This study is aimed at developing a
                 method of analysis of the 3D structure of a scene
                 considering a monocular image sequence, with an
                 uncalibrated camera -as for an active visual system-
                 and using a continuous model of motion. Surprisingly
                 perhaps, this problem has not been studied much in
                 literature except
                 \&bsol;cite\&lcub;vieville-faugeras:95\&rcub;, but only
                 preliminarly, and without any reference to active
                 vision. This difficulty might have its source in the
                 intrinsic complexity of the underlying equations, which
                 yields a heavy implementation and are thus a-priori not
                 robust. Moreover important developments of analytic
                 equations are not possible as it is the case for
                 calibrated systems \&bsol;cite\&lcub;vieville-clergue-
                 etal:95,chaumette-boukir:91,boukir:93\&rcub;, because
                 of the algebraic complexity of the equations. In order
                 to overcome this difficulty, we have attempted to
                 develop a simplified parameterization of the problem in
                 the case of two or more views, considering a scene with
                 a set of stationary objects and applying an
                 orthographic model of the projection. In this case,
                 fusion along the image sequence is trivial. Thanks to
                 the integration of active visual perception, we
                 demonstrate that it is always possible to generate a
                 displacement so that the previous model is valid, and
                 we can then very easily reconstruct the observed scene.
                 In the case where the motion constraints are
                 approximately verified, we can show that the model is
                 still approximately valid close to the retina. At an
                 experimental level, we report a small implementation
                 taking an image sequence as input, which allows us to
                 compute the retinal motion fields and calculate the
                 reconstruction up to a particular affine transform of
                 the scene.",
}

@TechReport{GROS,
  pages =        "40 p.",
  type =         "Technical Report",
  number =       "RR-2608",
  institution =  "Inria, Institut National de Recherche en Informatique
                 et en Automatique",
  title =        "Using geometric quasi-invariants to match and model
                 images of line segments",
  bibdate =      "July 1, 1995",
  author =       "Patrick Gros and Olivier Bournez and Edmond Boyer",
  language =     "A",
  abstract =     "L\&apos;appariement d\&apos;images consiste \&agrave;
                 retrouver dans deux ou plusieurs images les primitives
                 qui repr\&eacute;sentent une m\&ecirc;me primitive de
                 la sc\&egrave;ne C\&apos;est un processus de base de la
                 vision d\&egrave;s lors que l\&apos;on utilise
                 plusieurs images. Dans cet article, nous proposons un
                 algorithme d\&apos;appariement de deux images
                 bas\&eacute; sur l\&apos;utilisation de
                 quasi-invariants g\&eacute;om\&eacute;triques locaux.
                 Une fois le premier appariement
                 r\&eacute;alis\&eacute;, une approximation projective
                 du mouvement apparent et la g\&eacute;om\&eacute;trie
                 \&eacute;pipolaire sont utilis\&eacute;s pour le
                 compl\&eacute;ter. Dans le cas ou\&grave; l\&apos;on
                 dispose de plusieurs images, on peut, dans un premier
                 temps, les apparier deux par deux. La derni\&egrave;re
                 partie expose alors comment passer de ces appariements
                 partiels \&agrave; un appariement global de toutes les
                 images Image matching consists in finding in two images
                 the features which represent a same feature of the
                 observed scene. It is a basic process of vision as soon
                 as several images are used. use of local geometric
                 quasi- invariants. Once a first match is made, a
                 projective approximation of the apparent motion and the
                 epipolar geometry may be used to complete it. In the
                 case where we consider more than two images, these
                 images may be matched two by two in a first step, and a
                 global match is deduced in a second step: this is
                 exposed in the last section. The main advantages of the
                 method presented here are the following: it still works
                 even if the images are noisy and the polyhedral
                 approximation of the contours is not exact, if the
                 apparent motion between the images is not very small,
                 if the whole scene has not a single rigid motion, if
                 the camera is not calibrated and the camera motion
                 between the two shots is not known... It is thus usable
                 in many cases where no other method is available",
}

@Article{BURGE1,
  author =       "M. Burge and G. Monagan",
  title =        "Extracting Words and Multi-Part Symbols in Graphics
                 Rich Documents",
  journal =      "Lecture Notes in Computer Science",
  volume =       "974",
  pages =        "533",
  year =         "1995",
  coden =        "LNCSD9",
  ISSN =         "0302-9743",
  bibdate =      "Sat May 11 13:45:32 MDT 1996",
  acknowledgement = ack-nhfb,
}

@TechReport{FAUG,
  author =       "O. Faugeras and B. Hotz and H. Mathieu and T.
                 Vi\'{e}ville and Z. Zhang and P. Fua and E. Th\'{e}ron
                 and L. Moll and G. Berry and J. Vuillemin and P. Bertin
                 and C. Proy",
  title =        "Real time correlation-based stereo: algorithm,
                 implementatinos and applications",
  institution =  "Institut National De Recherche en Informatique et en
                 Automatique (INRIA)",
  year =         "1993",
  number =       "2013",
  address =      "06902 Sophia Antipolis, France",
}

@Article{IZ,
  author =       "M. {Ebroul Izquierdo} and S. Kruse",
  title =        "Image Analysis for {3D} Modeling, Rendering, and
                 Virtual View Generation",
  journal =      "Computer Vision and Image Understanding",
  volume =       "71",
  number =       "2",
  year =         "1998",
  coden =        "CVIUF4",
  ISSN =         "1077-3142",
  bibdate =      "Tue Sep 22 09:51:52 MDT 1998",
  acknowledgement = ack-nhfb,
}

@Article{TanNg98,
  author =       "C. L. Tan and P. O. Ng",
  title =        "Text Extraction Using Pyramid",
  journal =      "Pattern Recognition",
  pages =        "63--72",
  volume =       "31",
  number =       "1",
  year =         "1998",
}

@Article{Tan98,
  key =          "tan",
  author =       "T. N. Tan",
  title =        "From Image Quadrilaterals to Symmetrical Trapezia",
  journal =      "Pattern Recognition",
  pages =        "1117--1125",
  volume =       "31",
  number =       "8",
  year =         "1998",
}

@Article{espaper1,
  key =          "Petrou \&{} Kittler",
  author =       "M. Petrou and J. Kittler",
  title =        "Optimal Edge Detectors for Ramp Edges",
  journal =      "IEEE Transactions on Pattern Analysis and Machine
                 Intelligence",
  pages =        "483--491",
  volume =       "13",
  number =       "5",
  year =         "1991",
  location =     "E \&{} S Library",
}
  % month =        may,

@inproceedings{espaper,
  Html        = { <a name="Petrou94a">Petrou94a</a> },
        author = {M. Petrou},
        title = {{T}he Differentiating Filter Approach to Edge Detection},
        booktitle = {Advances in Electronics and Electron Physics},
        number = "88",
        publisher = {Academic Press},
        year = {1994},
        pages = {297-345}
}

@Article{htpaper,
  author =       "P. L. Palmer and J. Kittler and M. Petrou",
  title =        "An Optimizing Line Finder Using a {Hough} Transform
                 Algorithm",
  journal =      "Computer Vision and Image Understanding",
  volume =       "67",
  pages =        "1--23",
  number =       "1",
  year =         "1997",
  coden =        "CVIUF4",
  ISSN =         "1077-3142",
  bibdate =      "Tue Sep 22 09:51:52 MDT 1998",
  acknowledgement = ack-nhfb,
}

@Article{espaper2,
  key =          "Petrou \&{} Kittler",
  author =       "Maria Petrou and Josef Kittler",
  title =        "Optimal Edge Detectors for Ramp Edges",
  journal =      "IEEE Transactions on Pattern Analysis and Machine
                 Intelligence",
  pages =        "483--491",
  volume =       "PAMI-13",
  number =       "5",
  month =        may,
  year =         "1991",
  location =     "E \&{} S Library",
}



@Article{HONES,
  author =       "Frank Hones, Jurgen Lichter",
  title =        "Layout extraction of mixed mode documents",
  journal =      "Machine Vision and Applications",
  pages =        "237--246",
  volume =       "7",
  year =         "1994",
}

@Article{TIAN1,
  author =       "Tina Tian, Mubarak Shah",
  title =        "Estimating 3D motion and shape of multiple objects using {Hough} transform",
  journal =      "ICPR",
  volume = 	 "",
  year =         "1994",
}

@TechReport{LOWE,
  author =       "D. G. Lowe",
  title =        "Perceptual Organization and Visual Recognition",
  institution =  "Stanford University",
  year =         "1984",
  number =       "STAN-CS-84-1020",
  type =         "Report",
  address =      "Department of Computer Science",
  topics =       "K{\"u}nstliche Intelligenz / Raumwissen /
                 Neurowissenschaften / Psychophysik /
                 Mathematik/Geometrie / Konkreter Raum / Spatial
                 Reasoning",
}

@Book{LOW85,
  author =       "D. Lowe",
  title =        "Perceptual Organization and Visual Recognition",
  publisher =    "Kluwer Academic Publishers",
  year =         "1985",
}

@TechReport{FAUG2,
  pages =        "24 p.",
  type =         "Technical Report",
  number =       "RR-2572",
  institution =  "Inria, Institut National de Recherche en Informatique
                 et en Automatique",
  title =        "3-{D} Reconstruction of Urban Scenes from Sequences of
                 Images",
  bibdate =      "June 1, 1995",
  author =       "Stephane {Faugeras, Olivier\&sol; Laveau} and Luc
                 Robert and Cyril {Csurka, Gabriella \&sol; Zeller}",
  language =     "A",
}

@TechReport{GRAC,
  author="Nuno Gracias and Jose Santos-Victor",
  title="Robust Estimation of the Fundamental Matrix and Stereo Correspondences",
  institution="VisLab",
  journal="5th International Symposium on Intelligent Robotic Systems, SIRS97",
  bibdate="July 1997",
  number="TR 05-97",
}

@TechReport{MAR,
  author="Lionel Marce and Patrick Bouthemy",
  title="Determination of a depth map from an image sequence",
  institution="INRIA",
  bibdate="December 1987",
  number="765",
}

@Article{JAIN,
  author =       "A. K. Jain and S. Bhattacharjee",
  title =        "Text segmentation using {G}abor filters for automatic
                 document processing",
  journal =      "Machine Vision and Applications",
  year =         "1992",
  number =       "3",
  pages =        "169--184",
  volume =       "5",
}

@InProceedings{MSU,
  author =       "A. Jain and B. Yu and Y. Zhong and O. Trier and N. Ratha",
  title =        "Document Processing Research at {Michigan State University}",
  booktitle =      "Proceedings of the Symposium on Document Image Understanding Technology",
  year =         "1995",
  pages =        "126-140",
}
  % publisher =    "Bowie",

@Article{BERT,
  author =       "M. Bertozzi and A. Broggi and A. Fascioli",
  title =        "Stereo inverse perspective mapping: theory and applications",
  journal =      "Image and Vision Computing",
  year =         "1998",
  pages =        "585-590",
  volume =       "16",
}

@Article{LAWN,
  author =       "Jonathan Lawn and Robert Cipolla",
  title =        "Camera motion determination from dynamic perceptual grouping of line segments",
  journal =      "",
  year =         "",
  pages =        "",
  volume =       "",
}

@Article{HEYD,
  author =       "Anders Heyden and Kalle Astrom",
  title =        "A canonical framework for sequences of images",
  journal =      "",
  year =         "",
  pages =        "",
  volume =       "",
}

@InProceedings{TIAN2,
  author =       "T. Y. Tian and M. Shah",
  title =        "Motion segmentation and estimation",
  booktitle =    "Proceedings of the 1st International Conference on Image
                 Processing",
  volume =       "2",
  publisher =    "IEEE Comput. Soc. Press",
  address =      "Los Alamitos, CA",
  year =         "1994",
  pages =        "785--789",
}

@Article{FOREST,
  author =       "Gianluca Foresti and Vittorio Murino and Carlo S.
                 Regazzoni and Gianni Vernazza",
  key =          "Foresti et al.",
  title =        "Grouping of Rectilinear Segments by the Labeled
                 {Hough} Transform",
  journal =      "Computer Vision, Graphics, and Image Processing. Image
                 Understanding",
  volume =       "59",
  number =       "1",
  pages =        "22--42",
  month =        jan,
  year =         "1994",
  coden =        "CIUNEJ",
  ISSN =         "1049-9660",
  bibdate =      "Sat Sep 14 09:06:56 MDT 1996",
  acknowledgement = ack-nhfb,
  affiliation =  "Dept. of Biophys. and Electron. Eng., Genoa Univ.,
                 Italy",
  classification = "C1250 (Pattern recognition); C5260B (Computer vision
                 and picture processing)",
  keywords =     "Convergence; Edge labeling; Edge points; Graph;
                 Grouping edges; {Hough} space; Labeled {Hough} transform;
                 Parallelism; Rectilinear segments; Relational
                 properties; Straight lines",
  location =     "CMU E&S Library",
  thesaurus =    "Edge detection; {Hough} transforms",
}

@Article{VanGool:1995:CDS,
  author =       "Luc {Van Gool} and Theo Moons and Dorin Ungureanu and
                 Andre Oosterlinck",
  title =        "Characterization and detection of skewed symmetry",
  journal =      "Computer Vision and Image Understanding",
  volume =       "61",
  number =       "1",
  pages =        "138--150",
  month =        jan,
  year =         "1995",
  coden =        "CVIUF4",
  ISSN =         "1077-3142",
  bibdate =      "Fri Jan 31 15:09:26 MST 1997",
  acknowledgement = ack-nhfb,
  affiliation =  "Katholieke Universiteit Leuven",
  affiliationaddress = "Heverlee, Belgium",
  classification = "723.5; 741.2; 921.3; 931.1",
  journalabr =   "Comput Vision Image Process",
  keywords =     "Affine transformations; Collinearity constraint;
                 Computer vision; Constraint theory; Mathematical
                 transformations; Parallelism constraint; Skewed
                 symmetry; Surfaces",
}

@PhdThesis{rande-phd,
  author =       "Trygve Randen",
  title =        "Filter and Filter Bank Design for Image Texture
                 Recognition",
  year =         "1997",
  school =       "Norwegian University of Science and Technology",
  address =      "Trondheim, Norway",
  month =        oct,
  note =         "Also available at http://www.hsr.no/\~{ }tranden/",
}

@article{Yu96,
        AUTHOR = "Yu, B. and Jain, A.K.",
        TITLE = "A Robust and Fast Skew Detection Algorithm for Generic Documents",
        JOURNAL = "Pattern Recognition",
        VOLUME = "29",
        YEAR = "1996",
        NUMBER = "10",
        PAGES = "1599-1629"
}

@article{Amin96,
        AUTHOR = "Amin, A. and Fischer, S. and Parkinson, A.F. and Shiu, R.",
        TITLE = "Comparative-Study of Skew Detection Algorithms",
        JOURNAL = "Journal of Electronic Imaging",
        VOLUME = "5",
        YEAR = "1996",
        NUMBER = "4",
        PAGES = "443-451"}



@Article{messelod1,
  author =       "S. Messelodi and C. M. Modena",
  title =        "Automatic identification and skew estimation of
                  text lines in real scene images",
  journal =      "Pattern Recognition",
  volume =       "32",
  number = "5",
  year =         "1999",
  pages =        "791-810",
}
 
@Article{YIP,
  author =       "R. Yip",
  title =        "A {Hough} transform technique for the detection of reflectional symmetry and skew-symmetry",
  journal =      "Pattern Recognition Letters",
  volume =       "21",
  number = "2",
  pages =        "117--130",
  year =         "2000",
}





@InProceedings{LIDOERMANN,
  author =       "Huiping Li and David Doermann",
  title =        "Text Enhancement in Digital Video Using Multiple Frame
                 Integration",
  pages =        "19--22",
  booktitle =    "Proceedings of the 7th {ACM} International Multimedia
                 Conference",
  year =         "1999",
}
  % publisher =    "ACM Press",
  % month =        oct # "~30--" # nov # "~5",
  % address =      "N.Y.",

@InProceedings{KIJEONG,
  author =       "K.-Y. Jeong and K. Jung and H. J. Kim",
  title =        "Neural network-based text location for
                 news video indexing",
  pages =        "319--323",
  booktitle =    "Proceedings of the International Conference on
                 Image Processing",
  publisher =    "IEEE",
  year =         "1999",
}
 

% A Video Text Extraction Method for Character Recognition
% 
% Osamu Hori 
%  Toshiba Corporation
% 
%  This paper presents a method to precisely extract only video character portions from a video text rectangle region in order to make a readable image for OCR. In the conventional methods, gray image binarization processing with a given threshold is employed to extract high-intensity video character regions. A video has a complex background with various kinds of intensity so that appropriate thresholds are not always obtained. The proposed method extracts reliable high-intensity regions in a video text region and then expands them in order to make the whole video character regions. The experiments show this new method to be superior to the conventional methods.
% 
%  Keywords: Character recognition, Video text, Video analysis, Binarization, Histogram, Text extraction


@InProceedings{pilucvpr1,
  author =       "M. Pilu",
  title =        "Extraction of illusory linear clues in perspectively skewed documents",
  year =         "2001",
 booktitle = "IEEE Conf on Computer Vision and Pattern Recognition",
  pages = "363--368",
}
 


@InProceedings{taylorrecons00,
  author =       "D. Jelinek and C. J. Taylor",
  title =        "Reconstruction of Linearly Parameterized Models from
                 Single Images with a Camera of Unknown Focal Length",
  pages =        "346--352",
  booktitle =    "Proceedings of the {IEEE} Computer Science Conference
                 on Computer Vision and Pattern Recognition",
  year =         "1999",
}
 

@inproceedings{2001-clark,
  title={Estimating the Orientation and Recovery of Text Planes in a Single Image},
  author={Paul Clark and Majid Mirmehdi},
  Booktitle={Proceedings of the 12th British Machine Vision Conference},
  publisher={BMVA Press},
  pages={421--430},
  month={September},
  year={2001}
}
