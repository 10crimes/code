% Paper for submission to Pattern Recognition Letters

\documentclass{elsart}   %%[10pt]
%\usepackage[english]{babel}
\usepackage{amssymb}
\usepackage{pclark,epsfig,mysubfigure,comment}

% For revision highlighting
\usepackage[usenames]{color}
\newcommand{\newbyjoey}{
% \color{Red}
}

\begin{document}

\begin{frontmatter}

%%\title{Recognition of Text in 3D Scenes Using Vanishing Points}
\title{Rectifying Perspective Views of Documents in 3D Scenes Using Vanishing Points}

\author{Paul Clark and Majid Mirmehdi}  %%% \corauthref{cor1}}
%\ead{\{pclark,majid\}@cs.bris.ac.uk}
%%\corauth[cor1]{Corresponding author: pclark@cs.bris.ac.uk}

\address{
Department of Computer Science, Univerity of Bristol, Bristol BS8 1UB, UK %\\
%{\tt \{pclark|majid\}@cs.bris.ac.uk}
}

\begin{abstract}
Documents may be captured at any orientation when viewed with a camera.  Here, 
a method of recovering a fronto-parallel view of text documents is presented
in single images.
Analysis of standard 2D projection profiles is commonly used in
document recognition. We introduce a novel extension of this to locate the
horizontal vanishing point  of the text plane.  Following further analysis,
we segment the lines of text  to determine the style of
justification of the paragraphs.  The change in line spacings exhibited due to
perspective is then used to locate the document's vertical vanishing point. 
No knowledge of the camera focal length  is assumed. Using the vanishing
points, a fronto-parallel view is recovered. 
% suitable for OCR or other high-level recognition.  
We provide results demonstrating the algorithm's performance on
documents over a wide range of orientations.
\end{abstract}
%\maketitle

\begin{keyword}
Document Analysis and Recognition \sep Vanishing Point Detection \sep
Perspective Recovery \sep Paragraph Format
\end{keyword}
\end{frontmatter}

%\baselineskip 24pt
\small

\section{Introduction}
With the use of cheap and simple (digital) cameras becoming common-place in the 
home and the office, the demand for simple, instantaneous scanning of documents is
rising. Pointing a camera at a document, clicking a button to capture the image
and then using some software to interpret the text, as in OCR, has many
advantages. For example, it is fast and removes the need for a flatbed scanner, and allows
for non-contact point-and-click capture of text documents. However, difficulties
 arise if the view of the document is perspectively skewed. Then,
some form of rectification is necessary to obtain a fronto-parallel view of the
document plane to allow off-the-shelf OCR software the best chance of
interpretation. 

There has been little research into the recognition of text in real scenes in
which the text is oriented relative to the camera.  As well as for general OCR
document recognition, processing and compensating for perspective skew of text
has applications in assisting the disabled and/or visually impaired, vehicle
navigation (road signs) and control (number plates), wearable computing tasks
requiring knowledge of local text, and general automated tasks requiring the
ability to read where it is not possible to use a scanner. In recent years, we
have presented different methods for locating, segmenting and recovery of 
text in real
scenes \cite{joey1,ClarkICPR2000,2001-clark,justin,clark-ijdar-2001}. As a
result, we developed an approach for {\em estimating} the rectification of the
perspective view of a document \cite{2001-clark,clark-ijdar-2001}. In this work,
we address the issue in more depth and present a {\em robust} approach for
determining the vanishing points of a perspectively viewed document to rectify
the text plane into a fronto-parallel view. Our method is independent of the focal
length of the camera and document font size. Additionally, we analyse and show
the limits and range of orientations of the text documents to which our proposed
method can be applied.


%%% DISCUSS A BY-PRODUCT OF OUR APPROACH AS A PARAGRAPH RECOGNISER 


%\section{Previous work}
There are various works on correction of text documents, when rotated or skewed
in the view plane only, such as \cite{Yu96,Amin96,docsthrucams,messelod1}. 
%% Can add the messeldi work too or remove the docsthrucams
Most such methods correctly use 2D assumptions such as parallel lines in the
view plane to determine the parameters for rotational correction. 
However, other than our own previous work, the authors are aware of only two
other groups involved in perspective skew recovery of documents
\cite{pilucvpr1,dance02}. In \cite{pilucvpr1}, a method is presented on extraction of linear illusory clues in
skewed documents. Horizontal clues  are extracted from
a binarised input image where the characters, words (partial or full) and lines
are transformed into blobs. Association networks are then built based on the
relationships between neighbouring compact or elongated blobs. Using a pool of
horizontal clues, a partial rectification of the document is performed.
Vertical clues are then sought in this new intermediary image to help perform a
full rectification. However, as explained in \cite{pilucvpr1},  the vertical
rectification is dependent on the number of illusary clues obtained as well as
on how reliable they are. In \cite{dance02}, sets of parallel lines
corresponding to text lines and formatted column boundaries are grouped to 
estimate vanishing points which are then used for perspective correction.
The author does not establish how the sets of lines are originally obtained.
This approach provided only an estimation and was  tested on orientation
angles varying only $20^\circ$ between the optical axis of the camera and the
normal to the document. Furthermore, it also only works on fully formatted
(i.e. on both left and right 
side) paragraphs whereas our method will  recognise different types of
justifications in paragraphs of text and work for a much
wider range of orientations. A further important difference between our work and 
those of both \cite{pilucvpr1} and \cite{dance02} is that while their methods
are applied to whole images of a document as the only object in the scene, we have the ability to locate and segment
paragraphs in an image into seperate entities amongst other clutter in the image.
%%% Useful ref: Shu99 (see dance02) 


% \begin{comment}
Outside of the document recognition area there are  many works that
estimate the orientation of planar surfaces in still images 
using  repeating textures or specific object models based on some image features.
For example, Ribeiro and Hancock \cite{ribeiro}
observed affine distortions in power spectra of an image to find lines of
consistent texture indicating the vanishing points of a plane. Criminisi and
Zisserman \cite{zisserman} also used texture to find the vanishing points of a
plane,  first by finding the orientation of the vanishing line with normalised
auto-correlation, and then applying another similarity measure to find its position.
Text too has repetitive elements (characters and lines) but
these elements do not match each other, and also sometimes may cover only a
small area of the image.

%Their approach splits the 2D search into two 1D searches: first normalised
%auto-correlation is used to find the orientation of the vanishing line; they
%then introduce a projective correlation similarity measure to find the position
%of the vanishing line.  We too will adopt the sequential approach of finding one
%dimension of the solution at a time. However,

% Knowledge of the structure of text may guide
% Furthermore the regions we are examining may only fill a relatively small area of
% the plane, and are not of a high resolution.
% Therefore the general approach of using repeating textures to discover
% the orientation of the text does not directly apply to our problem.

Rother \cite{rother0} found vanishing points  corresponding  to the three mutual
orthogonal directions of the scene using the parallel lines commonly
available in architectural environments.
Murino and
Foresti \cite{MURIN} used a 3D Hough transform to estimate the orientation of
planar shapes with known rectilinear features.
Gool et al. \cite{vangool98planar} have employed invariants to recover scene geometry
from image points with known planar homologies.
All of these methods initially require selecting points in the image which are
believed to have a certain relationship in the scene.
In our work, we first detect probable paragraphs and lines of text in the image.
We then attempt to minimise the error between the points and a model constructed from
a-priori information about documents.
The fitting equation detects a set of points that satisfy the constraints
and finds parameters for the 
% However, the problem of choosing a set of points 
% FIX THE GOOL REVIEW
% Gool et al. 
% \cite{GOOL} %and Yip\cite{yip} 
% found the skewed symmetry of 2D shapes which have an axis of
% symmetry in the plane, allowing for affine recovery.  We require recovery from
% perspective transformation and, as with these latter works, we will use a priori
% information about the 2D shape we are observing.

Knowledge of the principal vanishing points of the plane on which text lies is
sufficient to recover a fronto-parallel view. The text lines of a paragraph
on a plane oriented relative to the camera  point towards
the horizontal vanishing point of the text plane in the image. We make the
reasonable assumption that a paragraph must display some sort of
 left,  right, centred or full  formatting, i.e. with straight margins on the
left and/or right, or if the text is centred, a central vertical line around which
the text is aligned.  In such cases, these vertical lines point toward the
vertical vanishing point of the text plane.  We have therefore concentrated our
work on the recovery of paragraphs using these principles to extract the
horizontal and vertical vanishing points. 
%since by inherent nature of paragraphs  some
%formatting and justification exists.  

One approach to building a model of a paragraph is the bottom-up grouping of
pixels into characters, words and lines. This can be a noisy and troublesome
process. Here, we use all of the global information about the paragraph at one
time.  The principle of 2D projection profiles are extended to the problem of
locating the horizontal vanishing point by maximising the separation of the
lines in the paragraph.  From this vanishing point we are then able to
accurately segment paragraphs into separate lines of text.  The segmented lines
are then analysed to reveal the style of justification or alignment of the
paragraph.  Depending on the type of paragraph, either the margins or the projective
spacings between the lines are used to find the vertical vanishing point. For
fully formatted paragraphs the vertical vanishing point is found
using the paragraph's straight margins. For all other paragraphs,  i.e. left,
right, or centrally formatted,  line spacings are analysed to find
the position of the vertical vanishing point accurately. 
The proposed method eliminates the need for knowledge of 
the focal length of the camera, hence the techniques are applicable to images
taken from cameras with unknown internal parameters.

 
 In \refsect{recoveryusinglines}
we briefly review our previous work which provides the input to the work
described here.  Section \ref{locatehvpsect} concentrates on locating the
horizontal vanishing point. This information is applied in Section
\ref{sec-parags} to determine the formatting style of paragraphs.
In Section \ref{sec-vertvanish}  we demonstrate our method of precisely
locating the vertical vanishing point. We evaluate 
the range of orientations our methods apply to for both vanishing points. 
We discuss our conclusions in \refsect{conclusions}.
\input{findtext.tex}
\input{horlines.tex}
\input{parags.tex}
\input{vertlines.tex}


\section{Discussion} \label{conclusions}

We have presented a novel approach to the fronto-parallel recovery of a wide
range of documents and paragraph formats under perspective transformation in a
single image, without knowledge of the focal length of the camera.  Projection
profiles from hypothesised vanishing points are used to robustly recover the
horizontal vanishing point of the text plane, and to segment the paragraph into
its constituent lines.  Line fitting on the margins and central line of the
document is then applied to deduce the formatting style of the paragraphs.  To
estimate the vertical vanishing point, for fully justified paragraphs the margin
lines are intersected.  For other styles of documents, the observed difference
in the spacings of the lines of text are used to retrieve the tilt of the text
plane, and hence the vertical vanishing point.  Using the two principal
vanishing points we find the orientation of the text plane and recover a
fronto-parallel view.  The algorithm performs well for all types of paragraphs,
provided it has some type of formatting. Hence, as a by-product of our proposed
method we have demonstrated how to understand the format of paragraphs which can 
be of many uses in the Document Recognition field.
In total the process takes around 20 seconds to recover a document,
demonstrating its potential and applicability 
%to realtime systems, as well as its suitability
for normal scanning tasks.
%An optimisation algorithm for the search for the horizontal vanishing point was presented.

%Whilst the described method is suitable for documents or single paragraphs, due
%to the use of margins or line spacing to recover the vertical vanishing point,
%there must be at least two lines present for fully justified paragraphs, and at
%least five for other styles of document, to provide enough data for an accurate
%fitting.  However, other forms of text appear in our environment, and it would
%also be desirable to retrieve these, especially in a realtime system for the
%visually impaired.  Examples of such situations include signs and notices, the
%names of shops on a high street, labels on everyday objects, and number plates.
%To retrieve such isolated lines of text from single images, use can be made of
%the fact that strong horizontal and vertical edges are exhibited by characters
%in many typefaces, providing clues to the orientation of the text.
%Alternatively, by using a video camera to track text regions over image
%sequences, the relative orientation of the text plane may be obtained by
%monocular structure-from-motion algorithms, allowing for fronto-parallel OCR as
%proposed in this work.

Although the resulting images reproduced here are at low resolution, most of
them are nevertheless suitable to be fed to an OCR system to interpret the text
or to be read by a human observer. 
In the future we intend to integrate the work described here and
in~\cite{justin} towards an automatic system for text recognition in the
environment, suitable for a wearable computer system. 

% {\bf acknowledgement}
% The authors would like to thank HP Research Labs, UK for their support.

\bibliographystyle{elsart-num}
\bibliography{jrefs}

\end{document}
